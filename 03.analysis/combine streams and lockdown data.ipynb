{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine streams and lockdown data\n",
    "The data we have so far is split in two tables (streaming data and lockdown stringency) with all the info per country in columns. In order to facilitate further investigation, we want to have one table per country with the number of streams and stringency factor combined per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "f1, f2 = [os.path.join(\"..\", \"02.cleaning\", filename)\n",
    "          for filename in\n",
    "          [\"aggregated_country_streams.pkl\", \"lockdown_clean.pkl\"]]\n",
    "st = pd.read_pickle(f1)\n",
    "ld = pd.read_pickle(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two functions to do the magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_index(df, mode):\n",
    "    \"\"\"Return a df with clean indices.\"\"\"\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # We need to flatten the multi-index column names\n",
    "        df.columns = df.columns.get_level_values(1)\n",
    "    col_names = list(df.columns)\n",
    "    \n",
    "    # Depending on which df, we set the name of the last column\n",
    "    col_names[0] = \"date\"\n",
    "    col_names[-1] = mode\n",
    "    df.columns = col_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "def focus_country(df, country, mode):\n",
    "    \"\"\"Return a df with only date, and specified country columns.\"\"\"\n",
    "    \n",
    "    col_names = list(df.columns)\n",
    "    \n",
    "    # We want to keep the date and specified country columns\n",
    "    if country == \"EU\":\n",
    "        to_drop = col_names[1: -1]\n",
    "    else:\n",
    "        col_names.pop(0)\n",
    "        col_names.remove(country)\n",
    "        to_drop = col_names\n",
    "    \n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "    \n",
    "    return df.rename(columns={country: mode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = clean_index(st, \"streams\")\n",
    "ld = clean_index(ld, \"stringency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The correct dtype of datetime in ld was lost, which is why the merge failed\n",
    "ld[\"date\"] = pd.to_datetime(ld[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of countries to loop over shortly\n",
    "countries = \"AUT, BEL, BGR, HRV, CYP, CZE, \\\n",
    "                DNK, EST, FIN, FRA, DEU, GRC, \\\n",
    "                HUN, IRL, ITA, LVA, LTU, LUX, \\\n",
    "                MLT, NLD, POL, PRT, ROU, SVK, \\\n",
    "                SVN, ESP, SWE, GBR\"\n",
    "countries = [c.strip() for c in countries.split(\", \") if c.strip() not in [\"HRV\", \"MLT\", \"SVN\"]]\n",
    "countries.append(\"EU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and export tables for all the countries\n",
    "for country in countries:\n",
    "    # First get rid of countries we're not intested in. \n",
    "    s = focus_country(st.copy(), country, \"streams\")\n",
    "    l = focus_country(ld.copy(), country, \"stringency\")\n",
    "    \n",
    "    # Then merge the two df's\n",
    "    merg = pd.merge(s, l, how='left', on='date')\n",
    "    \n",
    "    # And export to csv and pickle\n",
    "    path = os.path.join(\"merged_data\", country)\n",
    "    merg.to_csv(path + \".csv\")\n",
    "    merg.to_pickle(path + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
