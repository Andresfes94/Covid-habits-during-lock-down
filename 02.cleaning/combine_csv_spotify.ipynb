{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating streaming data from Spotify\n",
    "We now have 2800 csv files with weekly streaming data from the top 200 artists on Spotify. In this notebook we will look over the csv's to retrieve the weekly sum of streams and save it per country/week. Finally we save this data in a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.join(\"..\", \"01.raw_data\", \"spotify\")\n",
    "\n",
    "def aggregate_csv_streams(country):\n",
    "    \"\"\"Returns list with sum of weekly streams per country.\"\"\"\n",
    "    \n",
    "    # Get filenames in directory\n",
    "    country_base = os.path.join(base, country)\n",
    "    filenames = [filename for filename in os.listdir(country_base)]\n",
    "    data = []\n",
    "    \n",
    "    # Import all the csv data\n",
    "    for filename in filenames:\n",
    "        # filename format 2018-08-24--2018-08-31.csv\n",
    "        date = filename.split(\"--\")[0]\n",
    "        \n",
    "        # We use a try-except because certain files seem bogus\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(country_base, filename), header=1)\n",
    "            data.append({\"country\": country,\n",
    "                         \"date\": date,\n",
    "                         \"streams\": df[\"Streams\"].sum()})\n",
    "        except pd.errors.ParserError: \n",
    "            print(f\"{country} - {date}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {

     ]
    }
   ],
   "source": [
    "# For every country we take the data from the csv files. \n",
    "# The result will be a list of dictionaryies containing \n",
    "# country, week and num streams.\n",
    "# We use the append method because a list comprehension \n",
    "# might use too much memory\n",
    "\n",
    "data = []\n",
    "for country in os.listdir(base):\n",
    "    if (os.path.isdir(os.path.join(base, country)) \n",
    "            and not country.startswith(\".\")):\n",
    "        data.extend(aggregate_csv_streams(country))\n",
    "\n",
    "# Turns out there is no data for HR, MT and SI"
   ]
  },
  {
   "cell_type": "code",

   "source": [
    "# Check how much data we have now\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",

    }
   ],
   "source": [
    "# Save in dataframe and convert date type\n",
    "df = pd.DataFrame(data)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",

   "source": [
    "# 2 Lists to convert 2 letter codes to 3 letter codes\n",
    "countries = \"AUT, BEL, BGR, HRV, CYP, CZE, \\\n",
    "                DNK, EST, FIN, FRA, DEU, GRC, \\\n",
    "                HUN, IRL, ITA, LVA, LTU, LUX, \\\n",
    "                MLT, NLD, POL, PRT, ROU, SVK, \\\n",
    "                SVN, ESP, SWE, GBR\"\n",
    "iso3 = [c.strip() for c in countries.split(\", \")]\n",
    "iso2 = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', \n",
    "        'DK', 'EE', 'FI', 'FR', 'DE', 'GR', \n",
    "        'HU', 'IE', 'IT', 'LV', 'LT', 'LU', \n",
    "        'MT', 'NL', 'PL', 'PT', 'RO', 'SK', \n",
    "        'SI', 'ES', 'SE', 'GB']\n",
    "replacement = {k: v for k, v in zip(iso2, iso3)}\n",
    "\n",
    "df[\"country\"] = df[\"country\"].str.upper().replace(replacement)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table to have the weeks as index and streams per country column\n",
    "df = df.pivot(index=\"date\", columns=[\"country\"])"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the mean of all countries per week\n",
    "df[\"mean\"] = df.mean(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to pickle and csv\n",
    "df.to_pickle(\"aggregated_country_streams.pkl\")\n",
    "df.to_csv(\"aggregated_country_streams.csv\")"
   ]
  },
  {
   "cell_type": "code",

   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",

  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
